{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b96f19f5-a26b-4f82-bf3d-a976fe786abd",
   "metadata": {},
   "source": [
    "# Titanic Project: Will a Passenger Survive?\n",
    "Group 33 Members: Chloe Vaughan, Susan Zhang, James Drover, Olivia Klassen, and Adeeb Khan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8517e20a-a202-4f2b-ab74-df592371821e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introduction\n",
    "\n",
    "On the night of April 14th, 1912, the RMS Titanic struck an iceberg on her first trip in the Atlantic Ocean. Two hours and 40 minutes after the collision, the ship sank. This tragedy resulted in the loss of 1501 lives, which made up more than two-thirds of the total number of passengers and crew members (Frey et al., 2011). Less than half of the passengers survived, and of those passengers, many factors contributed to their survival or demise. Considering the many myths and ideologies surrounding the tragic incident, this project aims to observe the significance of various factors and the role they played in a passenger’s chance of survival. In this project, a dataset with information about the passengers aboard the Titanic and the status of their survival was read, wrangled, and classified in order to predict if a given passenger would have been likely to die in the accident.This analysis allows better understanding of the political environment during the which the Titanic sank. It is important to present and analyze this data so that we can think about how we might prioritize lives if a similar event were to occur. How was the lifeboat distribution prioritzied, and was it fair? Would we do things differently now, seeing as we have evolved towards equity as a society?  \n",
    "\n",
    "[The Titanic dataset](https://www.kaggle.com/competitions/titanic/data?select=train.csv) was obtained by Kaggle. \n",
    "\n",
    "**Question**: Will a given passenger survive the titanic crash? To answer this question, we must first ask what variables are important to determining survival.\n",
    "\n",
    "**Our Variables**:\n",
    "- PassengerId = **NOTE**: confused about this column, ALSO some variables from this list are later removed\n",
    "- Survived = whether the passenger lived or died on the Titanic, 0 = did not survive, 1 = survived\n",
    "- Passenger_Class = Indicates socio-economic status, 1 = Upper, 2 = Middle, 3 = Lower\n",
    "- Name = name of passenger\n",
    "- Age = age in years\n",
    "- Number0fSiblings = # of siblings/spouses on the titanic\n",
    "- NumberofParents_children = # of parents/children on the titanic \n",
    "- Ticket = ticket number\n",
    "- Fare = passenger fare\n",
    "- Cabin = cabin number\n",
    "- Embarked = Port of Embarkation, C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "\n",
    "The column names given above are not the same as the untidy data. We have renamed the columns in the original dataset. Familial relationships defined as follows:\n",
    "- Sibling = brother, sister, stepbrother, stepsister, Spouse = husband, wife, note that mistresses and fiancés were ignored\n",
    "- Parent = mother, father, some children travelled with a nanny, NumberofParents_children = 0 in this case. Child = daughter, son, stepdaughter, stepson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e6ba8c-26a5-4491-8991-8a8a8c397445",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Installing Packages & Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e4ce29-21f7-46c6-ae4f-aa966280d53b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "install.packages('themis')\n",
    "install.packages('psych')\n",
    "install.packages('gridExtra')\n",
    "install.packages(\"vctrs\")\n",
    "install.packages(\"kknn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057a12c5-bf31-4bf9-87e0-b11e626be7e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "library(vctrs)\n",
    "library(themis)\n",
    "library(tidyverse)\n",
    "library(tidymodels)\n",
    "library(dplyr)\n",
    "library(psych)\n",
    "library(gridExtra)\n",
    "library(kknn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267d5a8e-d2f8-4f3f-8e85-1afac3132835",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "Our first data anlysis step is to examine the data. Before we build our model, we need to read the data into R, then rename the columns with more intuitive names. Our next step is to become familiar with some statics on our data (e.g. number of observations, what each column means, can columns be dropped at this step, etc). We also need to wrangle our data into a tidy format. Some variables are changed to another class, and we examine how many NA values are present in our data. Tidy data ensures that the functions we employ later on work seamlessly, and makes the data easier to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e924fa88-07be-4a10-a88f-e58ab43cb3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "boat_data <- read_csv(\"data/train.csv\")\n",
    "colnames(boat_data) = c(\"PassengerId\", \"Survived\", \"Passenger_Class\", \"Name\", \"Sex\", \"Age\", \"Number0fSiblings\", \n",
    "                                 \"NumberofParents_children\", \"Ticket\", \"Fare\", \"Cabin\", \"Embarked\")\n",
    "head(boat_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff1dc9a-31d6-43b2-8bd1-e7f4ab767f75",
   "metadata": {},
   "source": [
    "Rarely are all the variables used to build a model, inclusion of too many can negatively impact our model's accuracy. Variables are excluded for several reasons: \n",
    "\n",
    "- 1) they may be a poor predictor of our target variable survival status \n",
    "- 2) too many NA values may be present and we have little data to work with \n",
    "- 3) the data collected is irrelevant, e.g. name, or enumeration of each entry in the data set\n",
    "\n",
    "In a later step, we run forward selection to determine which predictors are good ones. Right now, we only drop variables based on criteria 2) and 3). Table 1 shows detailed summary statistics for each variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fa2492-13cf-431d-a73b-90c303aef3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow(boat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6244eb56-849e-4a39-8693-8db91124f56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(boat_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80f3100-a9ed-42f0-88dd-9ae79bdc906e",
   "metadata": {},
   "source": [
    "**Table 1.** Summary Statistics for all Columns in Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bcd461-5f9d-4e71-857f-2c5eb1c1e858",
   "metadata": {},
   "source": [
    "Two variables under the count (n) column catch our eye; both Age and Cabin have quite a few NA values. We have decided to remove \"Cabin\" as a predictor because only 204 out of 891 observations (23%) are not NA (Table 1). In contrast, 714 out of 891 columns do have a value assigned for age, thus we keep this predictor as non-NA values constitute 80% of the total data. \n",
    "\n",
    "Some variables have drastically different scales, highlighting the importance of scaling to ensure each predictor has equal say. Also, the mean survival value is 38%, suggesting that most people did not survive the crash.\n",
    "\n",
    "We decided to drop Name, Ticket, and PassengerId as these variables contain information that is not relevant to our predictions. The Name, Ticket and passengerId are arbitrary, they do not hold information that will have a big impact. Below we remove the irrelevant predictors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfec793c-8360-4ed5-8e1d-cb96985fdcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting rid of PassengerId,Name, Embarked,Ticket and Cabin:\n",
    "boat_data_selected <- boat_data |>\n",
    "    select(-PassengerId,-Name, -Ticket, -Cabin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2937231d-4077-4696-9bd4-b0f51d742bd3",
   "metadata": {},
   "source": [
    "Two additional columns are added, one to turn sex into binary (1 = male, 0 = female), and another that converts the port of embarkation into numerical values (0 = Southampton, 1 = Cherbourg, 2 = Queenstown). We also remove NA values from age, and convert survived into a factor. The data type of each column is important to ensure all functions work seamlessly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90121d11-ea49-4f42-962e-e9ebf0746f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding a column for sex in binary and making the embarked column into numeric(for it to work with the knn model)\n",
    "\n",
    "boat_data_binary <- boat_data_selected |>\n",
    "    mutate(sex_binary = ifelse(Sex == \"male\", 1, ifelse(Sex == \"female\", 0, NA))) |>\n",
    "    mutate(Embarked_numeric = ifelse(Embarked == \"S\", 0, ifelse(Embarked == \"C\", 1, ifelse(Embarked == \"Q\", 2, NA))))\n",
    "\n",
    "boat_data_NA <- boat_data_binary |>\n",
    "    filter(!is.na(Age)) |>\n",
    "    mutate(Survived = as_factor(Survived))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c503d25c-c608-4287-a1dc-f3297f12e221",
   "metadata": {},
   "source": [
    "Before we begin exploratory data analysis, our data set has to be split. If we use testing data to build our model, we will not get a good evaluation of our model's accuracy. It already has \"experience\" with such data, thus we split our data into two sets; 70% to train our model, 30% to test it on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cce4784-0df8-4efe-a5fd-8265b01c71f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(911)\n",
    "#splitting the wrangled data into test and training sets\n",
    "#we chose a 70-30 percent split to ensure our model is accurate at the same time as making sure the testing is accurate.\n",
    "\n",
    "boat_split <- initial_split(boat_data_NA, prop = 0.7, strata = Survived)\n",
    "boat_train <- training(boat_split)\n",
    "boat_test <- testing(boat_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c28f76-66aa-477c-a1ee-224ac2c295a7",
   "metadata": {},
   "source": [
    "As of now, we have 7 possible predictors to determine \"survived\": Passenger_class, Sex, Age, Number0fSiblings, NumberofParents_children, Fare, and Embarked. The 7 figures below visualize the relationship between each of these predictors and survival status. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27bf2b4-5819-4ca7-a6f6-5dd6b9d1db18",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data_graph <- boat_train |>\n",
    "    mutate(Survived_char = ifelse(Survived == 1, \"Survived\", ifelse(Survived == 0, \"Did not survive\", NA)))\n",
    "\n",
    "survival_bar_plot_sex <- ggplot(temp_data_graph, aes(x = Sex, fill = as_factor(Survived_char))) +\n",
    "    geom_bar(position = \"fill\", col = \"black\") +\n",
    "    labs(x = \"Sex of passenger\", y = \"Percentage of survival\", fill = \"Survival\") +\n",
    "    ggtitle(\"Figure 1. Sex vs Survival \\nPredictor relation\") +\n",
    "    scale_fill_brewer(palette = \"Set1\") + \n",
    "    theme(text=element_text(size=15)) #Fare not yet explored\n",
    "\n",
    "NOC_survival <- temp_data_graph |>\n",
    "    ggplot(aes(x = NumberofParents_children, fill = as_factor(Survived_char))) +\n",
    "    geom_histogram(bins = 11, position = \"fill\", col = \"black\") +\n",
    "    labs(x = \"Number Of Children\", y = \"Percetage of Survival\", fill = \"Survived?\") + \n",
    "    scale_x_continuous(breaks = c(0, 1, 2,3,4,5)) +\n",
    "    ggtitle(\"Figure 2. Number Of Children vs \\nSurvival Predictor relation\") +\n",
    "    scale_fill_brewer(palette = \"Set1\") + \n",
    "    theme(text=element_text(size = 15))\n",
    "\n",
    "NOS_survival <- temp_data_graph |>\n",
    "    ggplot(aes(x = Number0fSiblings, fill = as_factor(Survived_char))) +\n",
    "    geom_histogram(bins = 11, position = \"fill\", col = \"black\") +\n",
    "    labs(x = \"Number Of Siblings\", y = \"Percetage of Survival\", fill = \"Survived?\") + \n",
    "    scale_x_continuous(breaks = c(0, 1, 2,3,4,5)) +\n",
    "    ggtitle(\"Figure 3. Number Of Siblings vs \\nSurvival Predictor relation\") +\n",
    "    scale_fill_brewer(palette = \"Set1\") +\n",
    "    theme(text=element_text(size = 15))\n",
    "\n",
    "class_survival <- temp_data_graph |>\n",
    "    ggplot(aes(x = Passenger_Class, fill = as_factor(Survived_char))) +\n",
    "    geom_histogram(bins = 7, position = \"fill\", col = \"black\") +\n",
    "    labs(x = \"Passenger Class\", y = \"Percetage of Survival\", fill = \"Survived?\") + \n",
    "    scale_x_continuous(breaks = c(0, 1, 2,3)) +\n",
    "    ggtitle(\"Figure 4. Passenger Class vs \\n Survival Predictor relation\") +\n",
    "    scale_fill_brewer(palette = \"Set1\") + \n",
    "    theme(text=element_text(size = 15))\n",
    "\n",
    "AgevSurvived <- temp_data_graph |>\n",
    "    ggplot(aes(x = Age, fill = as_factor(Survived_char))) +\n",
    "    geom_histogram(bins = 15, position = \"identity\", col = \"black\") +\n",
    "    labs(x = \"Age\", y = \"Number of People who Survived/Died\", fill = \"Survived?\")+\n",
    "    scale_x_continuous(breaks = seq(from = 0, to = 80, by = 15)) + \n",
    "    ggtitle(\"Figure 5. Age vs Survival \\nPredictor relation\") +\n",
    "    scale_fill_brewer(palette = \"Set1\") +  \n",
    "    theme(text=element_text(size = 15))\n",
    "\n",
    "EmbarkedvSurvived <- temp_data_graph |>\n",
    "    ggplot(aes(x = Embarked_numeric, fill = as_factor(Survived_char))) +\n",
    "    geom_histogram(bins = 3, position = \"identity\", col = \"black\") +\n",
    "    labs(x = \"Port of Embarkation\", y = \"Number of People who Survived/Died\", fill = \"Survived?\")+\n",
    "    scale_x_continuous() + \n",
    "    ggtitle(\"Figure 6. Port of Embarkation vs \\nSurvival Predictor relation\") +\n",
    "    scale_fill_brewer(palette = \"Set1\") +  \n",
    "    theme(text=element_text(size = 15))\n",
    "\n",
    "FarevSurvived <- temp_data_graph |> filter(Fare <275) |>\n",
    "    ggplot(aes(x = Fare, fill = as_factor(Survived_char))) +\n",
    "    geom_histogram(bins = 15, position = \"identity\", col = \"black\") +\n",
    "    labs(x = \"Fare\", y = \"Number of People who Survived/Died\", fill = \"Survived?\")+\n",
    "    scale_x_continuous(breaks = seq(from = 0, to = 285, by = 15)) + \n",
    "    ggtitle(\"Figure 7. Fare vs Survival \\nPredictor relation\") +\n",
    "    scale_fill_brewer(palette = \"Set1\") +  \n",
    "    theme(text=element_text(size = 15)) +\n",
    "     theme(axis.text.x = element_text(angle = 50, hjust = 1))\n",
    "\n",
    "options(repr.plot.width = 20, repr.plot.height = 15)\n",
    "grid.arrange(survival_bar_plot_sex, NOC_survival, NOS_survival, class_survival, AgevSurvived, EmbarkedvSurvived, FarevSurvived)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5267138c-3d2a-448a-949c-82068f2138ca",
   "metadata": {},
   "source": [
    "## Methods\n",
    "\n",
    "Using our cleaned up Titanic dataset, we decide to build a K-Nearest Neighbours Classification model to predict whether a passenger survived or not. This model operates by identifying the K nearest points to a new observation, then determines the survival status of a new observation by majority vote. Our predictors for identifying the K-nearest neighbours will be determined by forward selection, which sequentially addes predictors into our model's recipe then calculates the accuracy for each one. Identifying the best predictors is important, usage of irrelevant predictors induces random influence which corrupts the set of nearest neighbours to lower our model's accuracy. \n",
    "\n",
    "Following forward selection, we code our recipe using the predictors identified as well as the engine. We then run cross-validation to select the most accurate K value. Because our predictions are based on the K neighbours identified, the number of values we use to calculate the majority class will influence our end result, thus we try to use the best K value possible. Cross-validation is ideal because the accuracy is evaluated on a data set that was not used to build the model. Along with forward selection, cross-validation is another strategy to optimize our model \n",
    "\n",
    "We then use the predictors and K value identified to code our final model, and evalute its accuracy on the testing data. The percent accuracy of our model is a poor indicator of whether our model is good or not without a comparison. The baseline for any classification problem is the majority classifier, which will guess the majority classifier (0, dead in our case) regardless of the predictors' values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633874e9-5c97-4689-bef0-554ffd9a090d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Predictor Variable Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211f477b-5a86-41b6-a979-7bd83566ecfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(911)\n",
    "\n",
    "boat_train_model <- boat_train |>\n",
    "    select(-Sex)\n",
    "#Now we start the process of developing a model to predict weather a given passenger survived the titanic crash.\n",
    "\n",
    "boat_spec_tune <- knn_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) |>\n",
    "  set_engine(\"kknn\") |>\n",
    "  set_mode(\"classification\")\n",
    "\n",
    "boat_vfold <- vfold_cv(boat_train_model, v = 10, strata = Survived)\n",
    "k_vals <- tibble(neighbors = seq(from = 1, to = 35, by = 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1ec4ec-9d0f-40f3-90c7-c658aeaa193b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed(911)\n",
    "\n",
    "names <- c(\"Passenger_Class\", \"Age\", \"Number0fSiblings\", \"NumberofParents_children\", \"Fare\",\"sex_binary\",\"Embarked_numeric\")\n",
    "\n",
    "# create an empty tibble to store the results\n",
    "accuracies <- tibble(size = integer(), \n",
    "                     model_string = character(), \n",
    "                     accuracy = numeric())\n",
    "\n",
    "\n",
    "# store the total number of predictors\n",
    "n_total <- length(names)\n",
    "\n",
    "# stores selected predictors\n",
    "selected <- c()\n",
    "\n",
    "# for every size from 1 to the total number of predictors\n",
    "for (i in 1:n_total) {\n",
    "    # for every predictor still not added yet\n",
    "    accs <- list()\n",
    "    models <- list()\n",
    "    for (j in 1:length(names)) {\n",
    "        # create a model string for this combination of predictors\n",
    "        preds_new <- c(selected, names[[j]])\n",
    "        model_string <- paste(\"Survived\", \"~\", paste(preds_new, collapse=\"+\"))\n",
    "\n",
    "        # create a recipe from the model string\n",
    "        boat_recipe <- recipe(as.formula(model_string), \n",
    "                                data = boat_train_model) |>\n",
    "                          step_scale(all_predictors()) |>\n",
    "                          step_center(all_predictors())\n",
    "\n",
    "        # tune the KNN classifier with these predictors, \n",
    "        # and collect the accuracy for the best K\n",
    "        acc <- workflow() |>\n",
    "          add_recipe(boat_recipe) |>\n",
    "          add_model(boat_spec_tune) |>\n",
    "          tune_grid(resamples = boat_vfold, grid = k_vals) |>\n",
    "          collect_metrics() |>\n",
    "          filter(.metric == \"accuracy\") |>\n",
    "          summarize(mx = max(mean))\n",
    "        acc <- acc$mx |> unlist()\n",
    "\n",
    "        # add this result to the dataframe\n",
    "        accs[[j]] <- acc\n",
    "        models[[j]] <- model_string\n",
    "    }\n",
    "    jstar <- which.max(unlist(accs))\n",
    "    accuracies <- accuracies |> \n",
    "      add_row(size = i, \n",
    "              model_string = models[[jstar]], \n",
    "              accuracy = accs[[jstar]])\n",
    "    selected <- c(selected, names[[jstar]])\n",
    "    names <- names[-jstar]\n",
    "}\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a68eb6a-44e3-4c8e-a207-183a7d1d4b93",
   "metadata": {},
   "source": [
    "**Table 2.** Forward Selection Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395d7878-ed06-4a30-ab45-65b54a225e75",
   "metadata": {},
   "source": [
    "Forward selection (Table 2.) suggests that using 6 variables will give us the highest accuracy. Here, we use Fare, Sex_binary, Passenger_class, Age, Number0fSiblings, NumberofParents_children to build our recipe. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdba07d-b4de-44ae-8ecb-3f7c6c1eafa6",
   "metadata": {},
   "source": [
    "## Creating Initial Classification Engine & Finding the Best K Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616d8535-8fbe-4765-affa-d2efacb9f5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuning the model to find the best value of k using the best predictors as seen above.\n",
    "\n",
    "boat_recipe <- recipe(Survived ~ Fare +sex_binary + Passenger_Class + Age + Number0fSiblings, data = boat_train_model) |>\n",
    "    step_scale(all_predictors()) |>\n",
    "    step_center(all_predictors())\n",
    "\n",
    "boat_model_stats <- workflow() |>\n",
    "  add_recipe(boat_recipe) |>\n",
    "  add_model(boat_spec_tune) |>\n",
    "  tune_grid(resamples = boat_vfold, grid = k_vals) |>\n",
    "  collect_metrics() |>\n",
    "  filter(.metric == \"accuracy\")\n",
    " \n",
    "boat_model_stats\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b100c9a-5366-4750-89e8-ebb3b0306e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 10, repr.plot.height = 8)\n",
    "\n",
    "accuracy_versus_k <- ggplot(boat_model_stats, aes(x = neighbors, y = mean))+\n",
    "       geom_point() +\n",
    "       geom_line(color = \"blue\") +\n",
    "       labs(x = \"Neighbors\", y = \"Accuracy Estimate\") +\n",
    "       scale_x_continuous(breaks = seq(0, 35, by = 2))\n",
    "       scale_y_continuous(limits = c(0.4, 1.0))\n",
    "\n",
    "accuracy_versus_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027a399b-9ac7-4d26-9ec2-2fe2f0a9600c",
   "metadata": {},
   "source": [
    "**Figure 8.** Cross-Validation K Values Plot. The best accuracy is when K=5. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af59c5ff-322d-430d-80a9-79222cb15c1b",
   "metadata": {},
   "source": [
    "## Creating Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730623fb-eb3c-43d2-9543-2a1505a86b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(911)\n",
    "#pulling the max value of k and retraining the model with given k:\n",
    "\n",
    "kmax <- boat_model_stats|>\n",
    "    filter(mean == max(mean)) |>\n",
    "    pull(neighbors)\n",
    "\n",
    "boat_spec <- knn_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = kmax) |>\n",
    "  set_engine(\"kknn\") |>\n",
    "  set_mode(\"classification\")\n",
    "\n",
    "boat_fit <- workflow() |>\n",
    "  add_recipe(boat_recipe) |>\n",
    "  add_model(boat_spec) |>\n",
    "  fit(data = boat_train_model)\n",
    "\n",
    "kmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9bea2b-96ec-4c23-9917-b086faac2f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(911)\n",
    "#testing the model's accuracy on testing data:\n",
    "\n",
    "accuracy_estimate <- predict(boat_fit, boat_test) |>\n",
    "    bind_cols(boat_test) |>\n",
    "    metrics(truth = Survived, estimate = .pred_class) |>\n",
    "    filter(.metric == \"accuracy\")\n",
    "\n",
    "accuracy_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c730099b-1f9e-4384-b4f9-96df52014869",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the majority class prediction:\n",
    "\n",
    "majority_class <- boat_test |>\n",
    "    group_by(Survived) |>\n",
    "    summarise(count = n(), percentage = n()/nrow(boat_test))\n",
    "\n",
    "majority_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c209fd-e5d2-4b77-95d4-6c6284b67caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions <- predict(boat_fit, boat_test) |>\n",
    "    bind_cols(boat_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2a2779-7974-4dcf-ad0c-87cdbddaa159",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 8, repr.plot.height = 8)\n",
    "\n",
    "confusion_matrix <- predictions |>\n",
    "    conf_mat(truth = Survived, estimate = .pred_class)\n",
    "\n",
    "confusion_matrix\n",
    "\n",
    "autoplot(confusion_matrix,type = \"heatmap\", Truth =\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b00ebc5-6703-4870-88f7-f3bf9ca91114",
   "metadata": {},
   "source": [
    "**Figure 9.** Confusion matrix of our model's accuracy. For passengers that died, 106 predictions were correct out of 126. 67 were correctly predicted to survive out of 89 total."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685dd058-b7da-439b-94e0-0500609d4f12",
   "metadata": {},
   "source": [
    "## Final Analysis of our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a008e66-d07e-4ebf-97e4-6bb5eccc3447",
   "metadata": {},
   "outputs": [],
   "source": [
    "#slighly more accurate for males due to more males being in the training set\n",
    "\n",
    "predictions %>%\n",
    "group_by(sex_binary, Survived == .pred_class) %>%\n",
    "summarize(count = n()) %>%\n",
    "mutate(prop = count/sum(count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc072ef9-6744-4e75-80f5-e6e88cf47a71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "survivalvPredicted <- predictions %>%\n",
    "group_by(Survived, is_accurate = Survived == .pred_class) %>%\n",
    "summarize(count = n()) %>%\n",
    "mutate(prop = count/sum(count)) %>%\n",
    "filter(is_accurate) %>%\n",
    "ggplot()+\n",
    "geom_bar(aes(x = Survived, y = prop), stat = \"identity\", fill = \"deepskyblue\", col = \"black\") + \n",
    "labs(x = \"Survived? (1 is True)\", y = \"Accuracy (in percent)\") +\n",
    "ggtitle(\"Figure 10. Survived vs Percentage accuracy\") + \n",
    "theme(text=element_text(size = 15))\n",
    "\n",
    "classvPredicted <- predictions %>%\n",
    "group_by(Passenger_Class, is_accurate = Survived == .pred_class) %>%\n",
    "summarize(count = n()) %>%\n",
    "mutate(prop = count/sum(count)) %>%\n",
    "filter(is_accurate) %>%\n",
    "ggplot()+\n",
    "geom_bar(aes(x = Passenger_Class, y = prop), stat = \"identity\", fill = \"deepskyblue\", col = \"black\") + \n",
    "labs(x = \"Passenger Class\", y = \"Accuracy (in percent)\") +\n",
    "ggtitle(\"Figure 11. Passenger Class vs Percentage accuracy\") + \n",
    "theme(text=element_text(size = 15))\n",
    "\n",
    "FarevPredicted <- predictions |> mutate(accuracy =  Survived == .pred_class) |> filter(Fare <150) |>\n",
    "    ggplot(aes(x = Fare, fill = as_factor(accuracy))) +\n",
    "    geom_histogram(bins = 10, col = \"black\") +\n",
    "    labs(x = \"Fare\", y = \"Number of People at that fare\", fill = \"Accurately precited?\")+\n",
    "    scale_x_continuous(breaks = seq(from = 0, to = 275, by = 20)) + \n",
    "    ggtitle(\"Figure 12. Fare vs Accuracy Prediction accuracy\") +\n",
    "    scale_fill_brewer(palette = \"Set1\") +  \n",
    "    theme(text=element_text(size = 15))\n",
    "\n",
    "sexvPredicted <- predictions |> mutate(accuracy =  Survived == .pred_class) |>\n",
    "    ggplot(aes(x = Sex, fill = as_factor(accuracy))) +\n",
    "    geom_bar(bins = 2, col = \"black\") +\n",
    "    labs(x = \"Sex\", y = \"Number of People of given sex\", fill = \"Accurately predicted?\") +\n",
    "    ggtitle(\"Figure 13. Sex vs Accuracy Prediction accuracy\") +\n",
    "    scale_fill_brewer(palette = \"Set1\") +  \n",
    "    theme(text=element_text(size = 15))\n",
    "\n",
    "options(repr.plot.width = 8, repr.plot.height = 10)\n",
    "grid.arrange(survivalvPredicted, classvPredicted, FarevPredicted, sexvPredicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405dedc9-11da-437a-b661-143f76f88aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 8, repr.plot.height = 10)\n",
    "\n",
    "predictions %>%\n",
    "group_by(Passenger_Class, is_accurate = Survived == .pred_class) %>%\n",
    "summarize(count = n()) %>%\n",
    "mutate(prop = count/sum(count)) %>%\n",
    "filter(is_accurate) %>%\n",
    "ggplot()+\n",
    "geom_bar(aes(x = Passenger_Class, y = prop), stat = \"identity\", fill = \"deepskyblue\", col = \"black\") + \n",
    "labs(x = \"Passenger Class\", y = \"Accuracy (in percent)\") +\n",
    "ggtitle(\"Figure 11. Passenger Class vs Percentage accuracy\") + \n",
    "theme(text=element_text(size = 15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ef002a-f273-4c89-84c4-294c1d4db7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fare\n",
    "\n",
    "FarevPredicted <- predictions |> mutate(accuracy =  Survived == .pred_class) |> filter(Fare <150) |>\n",
    "    ggplot(aes(x = Fare, fill = as_factor(accuracy))) +\n",
    "    geom_histogram(bins = 10, col = \"black\") +\n",
    "    labs(x = \"Fare\", y = \"Number of People at that fare\", fill = \"Accurately precited?\")+\n",
    "    scale_x_continuous(breaks = seq(from = 0, to = 275, by = 20)) + \n",
    "    ggtitle(\"Figure 12. Fare vs Accuracy Prediction accuracy\") +\n",
    "    scale_fill_brewer(palette = \"Set1\") +  \n",
    "    theme(text=element_text(size = 15))\n",
    "\n",
    "FarevPredicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e333d1bf-6f7d-4137-9d9f-149b96bea98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sexvPredicted <- predictions |> mutate(accuracy =  Survived == .pred_class) |>\n",
    "    ggplot(aes(x = Sex, fill = as_factor(accuracy))) +\n",
    "    geom_bar(bins = 2, col = \"black\") +\n",
    "    labs(x = \"Sex\", y = \"Number of People of given sex\", fill = \"Accurately predicted?\") +\n",
    "    ggtitle(\"Figure 13. Sex vs Accuracy Prediction accuracy\") +\n",
    "    scale_fill_brewer(palette = \"Set1\") +  \n",
    "    theme(text=element_text(size = 15))\n",
    "\n",
    "sexvPredicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abe63c1-5b2f-4364-bf0f-a2fc32df2dd3",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8df029-ed2a-4b5f-b7c6-d2a7e19bb2be",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Frey, B. S., Savage, D. A., & Torgler, B. (2011). Behavior under Extreme Conditions: The Titanic Disaster. Journal of Economic Perspectives, 25(1), 209–222. https://doi.org/10.1257/jep.25.1.209\n",
    "\n",
    "Hall, W. (1982) Social Class and Survival on the S.S. Titanic. Social Science & Medicine, 22(6), 687-690.  https://doi.org/10.1016/0277-9536(86)90041-9  \n",
    "\n",
    "Titanic - Machine learning from disaster. (n.d.). Kaggle. https://www.kaggle.com/competitions/titanic/data?select=train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55182cf5-79eb-46ad-93c1-9afeac8086cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
